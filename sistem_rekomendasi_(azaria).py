# -*- coding: utf-8 -*-
"""Sistem Rekomendasi (Azaria).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uMTJ915qy0DGKajuY1B7E-nBCaMiRoQ6

# Import Library

Sel ini berisi semua library yang dibutuhkan untuk proyek ini. Library yang diimport adalah:
- **numpy (np)**: untuk operasi numerik dan array, seperti membuat array, matriks, dan melakukan operasi matematika pada array
- **matplotlib.pyplot (plt)**: untuk membuat visualisasi statis, interaktif, dan animasi, seperti membuat plot garis, scatter plot, histogram, dan sebagainya.
- **pandas (pd)**: untuk manipulasi dan analisis data, seperti membaca dan menulis data dari berbagai format file, membersihkan data, dan melakukan agregasi data.
- **seaborn (sns)**: untuk membuat visualisasi statistik yang informatif dan menarik, seperti membuat heatmap, violin plot, dan pair plot.
- **sklearn**: untuk membangun model machine learning, seperti model klasifikasi, regresi, dan clustering. Beberapa modul yang digunakan adalah:
1. **feature_extraction.text**: untuk mengekstrak fitur dari teks, seperti menghitung frekuensi kata atau menggunakan metode TF-IDF.
2. **metrics.pairwise**: untuk menghitung jarak atau kemiripan antara data, seperti menghitung cosine similarity.
- **tensorflow**: untuk membangun dan melatih model deep learning, seperti model neural network.
- **google.colab**: untuk mengakses fitur-fitur Google Colab, seperti mengupload file dan mendownload dataset.
"""

!pip install tensorflow

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from tensorflow import keras
from tensorflow.keras import layers
import tensorflow
from google.colab import files

"""# Membaca Data

Bagian ini digunakan untuk membaca data dari file CSV.

- `files.upload()` digunakan untuk mengupload file ke Google Colab.
- `!kaggle datasets download -d arashnic/book-recommendation-dataset` digunakan untuk mengunduh dataset dari Kaggle.
- `!unzip book-recommendation-dataset.zip` digunakan untuk mengekstrak file zip yang telah diunduh.
- `pd.read_csv()` digunakan untuk membaca data dari file CSV dan menyimpannya ke dalam DataFrame pandas.
"""

files.upload()
!kaggle datasets download -d arashnic/book-recommendation-dataset
!unzip book-recommendation-dataset.zip
books = pd.read_csv('/content/Books.csv')
ratings = pd.read_csv('/content/Ratings.csv')

books.head()

ratings.head()

"""# Eksplorasi Data Analysis (EDA)

Bagian ini digunakan untuk melakukan eksplorasi data analysis (EDA) untuk memahami karakteristik data.

`shape`: untuk melihat dimensi data (jumlah baris dan kolom).

"""

books.shape

ratings.shape

"""`info()`: untuk melihat informasi umum tentang data, seperti tipe data, jumlah data yang hilang, dan sebagainya."""

books.info()

ratings.info()

"""`describe()`: untuk melihat statistik deskriptif data, seperti mean, median, standar deviasi, dan sebagainya."""

books.describe()

ratings.describe()

"""# Preprocessing Data

Bagian ini bertujuan untuk membersihkan dan mempersiapkan data sebelum digunakan untuk membangun model.

`rename()`: mengubah nama kolom pada DataFrame `ratings` dan `books` agar lebih mudah diakses.
"""

ratings = ratings.rename(columns={'Book-Rating': 'rating','User-ID':'user_id'})
books = books.rename(columns={'Book-Title': 'book_title','Book-Author':'book_author','Year-Of-Publication':'year_of_publication','Image-URL-S':'Image_URL_S','Image-URL-M':'Image_URL_M','Image-URL-L':'Image_URL_L'})

"""Sel di bawah digunakan untuk membatasi jumlah data yang digunakan untuk mempercepat proses training model. Ini adalah pilihan opsional dan dapat diubah sesuai kebutuhan."""

books = books[:10000]
ratings=ratings[:5000]

"""Kode selanjutnya bertujuan untuk mencari buku-buku dengan rating tertinggi dan menyimpannya dalam list `best_books`.

"""

ratings[ratings.rating == max(ratings.rating)]
best_booksId = ratings.ISBN[ratings.rating == max(ratings.rating)]
best_booksId = list(dict.fromkeys(best_booksId))

best_books = []
for i in best_booksId:
    books_name = books.book_title[books.ISBN == i]
    best_books.append(books_name)

len(best_books)

"""Sel di bawah digunakan untuk membuat visualisasi distribusi rating buku
 dan tahun publikasi buku dalam bentuk bar chart.
"""

count = ratings["rating"].value_counts()
count.plot(kind='bar', title="Rating");

count = books["year_of_publication"].value_counts()

# Urutkan data berdasarkan tahun
count = count.sort_index()

plt.figure(figsize=(12, 6))  # Sesuaikan ukuran figure
sns.barplot(x=count.index, y=count.values, palette="viridis")  # Gunakan seaborn dan palette yang menarik

plt.title("Year of Publication", fontsize=16)  # Perbesar ukuran font judul
plt.xlabel("Year", fontsize=12)  # Perbesar ukuran font label sumbu x
plt.ylabel("Number of Books", fontsize=12)  # Perbesar ukuran font label sumbu y
plt.xticks(rotation=45, ha="right", fontsize=10)  # Rotasi label sum

"""Membuat matriks scatter plot dari semua pasangan kolom numerik dalam DataFrame `ratings`, serta histogram atau kernel density estimate (KDE) untuk setiap kolom individual pada diagonal.
- `ratings`: DataFrame yang berisi data yang akan divisualisasikan.
- `diag_kind='kde'`: Menentukan jenis plot yang akan ditampilkan pada diagonal. Dalam kasus ini, `'kde'` menunjukkan bahwa kernel density estimate (KDE) akan digunakan untuk memvisualisasikan distribusi data pada diagonal.

Tujuan: Membantu dalam memahami hubungan dan distribusi antar variabel numerik dalam data. Pair plot memberikan gambaran visual yang cepat tentang korelasi, outlier, dan pola dalam data.
"""

sns.pairplot(ratings, diag_kind = 'kde')

"""Menghapus baris yang mengandung nilai missing (NaN) dari DataFrame `books` dan `ratings`.

Tujuan: Membersihkan data dengan menghilangkan baris yang tidak lengkap, sehingga data yang digunakan untuk analisis lebih valid.
"""

books = books.dropna()
ratings = ratings.dropna()

"""Menghapus baris duplikat dari DataFrame `books` dan `ratings`.

Tujuan: Membersihkan data dengan memastikan setiap baris data unik, sehingga menghindari bias dalam analisis.
"""

ratings = ratings.drop_duplicates()
books = books.drop_duplicates()

books.shape

ratings.shape

"""Melihat sekilas struktur dan isi data dalam DataFrame setelah proses pembersihan data dilakukan. Ini berguna untuk verifikasi dan memastikan data telah bersih dan siap untuk tahap selanjutnya."""

books.head()

"""# Content-Based Filtering (Rekomendasi Berdasarkan Penulis)

Bagian ini mengimplementasikan sistem rekomendasi berbasis konten, dengan fokus pada penulis buku.

Data buku diubah menjadi DataFrame baru bernama `book` yang hanya berisi kolom yang relevan.
"""

book_ISBN = books['ISBN'].tolist()
book_title = books['book_title'].tolist()
book_author = books['book_author'].tolist()
book_year_of_publication = books['year_of_publication'].tolist()

book = pd.DataFrame({
    'book_ISBN': book_ISBN,
    'book_title': book_title,
    'book_author': book_author,
    'book_year_of_publication': book_year_of_publication
})

"""`TfidfVectorizer` digunakan untuk membuat representasi numerik dari penulis buku berdasarkan frekuensi kemunculan kata dalam nama penulis."""

tf = TfidfVectorizer()
tf.fit(book['book_author'])
tf.get_feature_names_out()

tfidf_matrix = tf.fit_transform(book['book_author'])
tfidf_matrix.shape

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=book.book_title
).sample(10, axis=1,replace=True).sample(10, axis=0)

"""`cosine_similarity` digunakan untuk menghitung kemiripan antar buku berdasarkan representasi TF-IDF dari penulisnya."""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

cosine_sim_df = pd.DataFrame(cosine_sim, index=book['book_title'], columns=book['book_title'])

"""Fungsi `author_recommendations` dibuat untuk memberikan rekomendasi buku berdasarkan kemiripan penulis dengan buku yang telah dibaca."""

def author_recommendations(i, M, items, k=10):
    ix = M.loc[:,i].to_numpy().argpartition(range(-1,-k,-1))
    closest = M.columns[ix[-1:-(k+2):-1]]
    closest = closest.drop(i, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

books_that_have_been_read = "The Diaries of Adam and Eve"
book[book.book_title.eq(books_that_have_been_read)]

recommendations = author_recommendations(books_that_have_been_read, cosine_sim_df, book[['book_title', 'book_author']])
recommendations = recommendations.drop_duplicates()
recommendations

"""- Memfilter DataFrame `books` dan mengambil baris di mana kolom `book_title` sama dengan nilai variabel `books_that_have_been_read` (buku yang telah dibaca). Hasilnya disimpan dalam variabel `books_that_have_been_read_row`. Tujuan: Mendapatkan informasi lengkap tentang buku yang telah dibaca, termasuk penulisnya, dari DataFrame `books`.
- Mengambil nilai dari kolom `book_author` (penulis buku) dari baris pertama (indeks 0) pada DataFrame `books_that_have_been_read_row`. Nilai ini kemudian disimpan dalam variabel `books_that_have_been_read_author`. Tujuan: Mendapatkan nama penulis dari buku yang telah dibaca.
"""

books_that_have_been_read_row = books[books.book_title == books_that_have_been_read]
books_that_have_been_read_author = books_that_have_been_read_row.iloc[0]["book_author"]

"""Mengambil kolom `book_author` dari DataFrame `recommendations` (hasil rekomendasi buku) dan menyimpannya dalam variabel `book_recommendation_authors`. Tujuan: Mendapatkan daftar penulis dari buku-buku yang direkomendasikan."""

book_recommendation_authors = recommendations.book_author

"""Melakukan iterasi dan memeriksa apakah penulis buku yang direkomendasikan sama dengan penulis buku yang telah dibaca. Jika sama, variabel `real_author` akan diincrement (ditambah 1). Tujuan: Menghitung jumlah buku yang direkomendasikan yang memiliki penulis yang sama dengan buku yang telah dibaca. Ini digunakan untuk mengevaluasi akurasi model rekomendasi."""

real_author = 0
for i in range(5):
    if book_recommendation_authors[i] == books_that_have_been_read_author:
        real_author+=1

"""Menghitung akurasi model rekomendasi dengan membagi jumlah buku yang direkomendasikan dengan penulis yang sama (`real_author`) dengan total jumlah buku yang direkomendasikan dan mengalikannya dengan 100. Hasilnya kemudian dicetak ke konsol. Tujuan: Mengevaluasi seberapa baik model rekomendasi dalam merekomendasikan buku-buku dari penulis yang sama dengan buku yang telah dibaca oleh pengguna."""

Accuracy = real_author/5*100
print("Accuracy of the model is {}%".format(Accuracy))

"""# Collaborative Filtering (Rekomendasi Berdasarkan Rating Pengguna)
## Encoding User dan Book ID

Mengubah `user_id` dan `ISBN` (yang mungkin berupa string atau angka yang tidak berurutan) menjadi representasi numerik (integer) yang berurutan mulai dari 0.

Tujuan: Mempersiapkan data agar dapat diproses oleh model deep learning, yang biasanya membutuhkan input numerik.

Dictionary Encoding:
- `user_to_user_encoded`: Memetakan `user_id` asli ke nilai integer yang dienkode.
- `user_encoded_to_user`: Memetakan nilai integer yang dienkode kembali ke `user_id` asli.
- `book_to_book_encoded`: Memetakan `ISBN` asli ke nilai integer yang dienkode.
- `book_encoded_to_book`: Memetakan nilai integer yang dienkode kembali ke `ISBN` asli.
"""

user_ids = ratings['user_id'].unique().tolist()
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}

book_ids = ratings['ISBN'].unique().tolist()
book_to_book_encoded = {x: i for i, x in enumerate(book_ids)}
book_encoded_to_book = {i: x for i, x in enumerate(book_ids)}

ratings['user'] = ratings['user_id'].map(user_to_user_encoded)
ratings['book'] = ratings['ISBN'].map(book_to_book_encoded)

"""# Dokumentasi Persiapan Data untuk Collaborative Filtering
## Menghitung Jumlah User dan Book

Menghitung jumlah total user dan buku yang unik dalam dataset. Tujuan: Informasi ini akan digunakan dalam membangun arsitektur model deep learning, khususnya untuk menentukan ukuran layer embedding.
"""

num_users = len(user_encoded_to_user)
print(num_users)

num_book = len(book_encoded_to_book)
print(num_book)

"""## Mengubah Tipe Data Rating dan Normalisasi

- Mengubah tipe data kolom `rating` menjadi `float32` untuk kompatibilitas dengan TensorFlow.
- Melakukan normalisasi nilai rating ke rentang 0 hingga 1 menggunakan Min-Max scaling.

Tujuan:
- Memastikan data rating dalam format yang sesuai untuk model deep learning.
- Normalisasi membantu meningkatkan performa dan stabilitas model dengan membawa nilai rating ke skala yang sama.
"""

ratings['rating'] = ratings['rating'].values.astype(np.float32)

min_rating = min(ratings['rating'])
max_rating = max(ratings['rating'])

print('Number of User: {}, Number of Books: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_book, min_rating, max_rating
))

"""## Mengacak Data

Mengacak urutan baris dalam DataFrame `ratings`.

Tujuan: Memastikan data training dan validasi terdistribusi secara acak, sehingga model tidak belajar pola yang tidak diinginkan dari urutan data asli. `random_state=42` digunakan untuk memastikan pengacakan yang sama setiap kali kode dijalankan.
"""

ratings = ratings.sample(frac=1, random_state=42)
ratings

"""## Membagi Data menjadi Input (x) dan Output (y)

Memisahkan data menjadi variabel input (x) dan output (y).

Tujuan: Menyiapkan data dalam format yang dibutuhkan oleh model deep learning.
- `x`: Berisi pasangan `user` dan `book` yang dienkode, merepresentasikan interaksi antara user dan buku.
- `y`: Berisi nilai rating yang telah dinormalisasi, merepresentasikan target yang ingin diprediksi oleh model.
"""

x = ratings[['user', 'book']].values
y = ratings['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

"""## Membagi Data menjadi Training dan Validasi

Membagi data input (x) dan output (y) menjadi data training dan data validasi.

Tujuan:
- Data training digunakan untuk melatih model deep learning.
- Data validasi digunakan untuk mengevaluasi performa model selama proses training dan mencegah overfitting.

Proporsi Pembagian: Dalam kasus ini, 70% data digunakan untuk training dan 30% untuk validasi.
"""

train_indices = int(0.70 * ratings.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""## Kelas `RecommenderNet`

Mendefinisikan arsitektur model deep learning untuk Collaborative Filtering. Kelas ini merupakan subclass dari `tf.keras.Model`, yang menyediakan struktur dasar untuk membangun model di TensorFlow.

Tujuan: Merepresentasikan model yang akan mempelajari pola dari data rating dan digunakan untuk memprediksi rating buku yang belum dibaca oleh user.

###Metode `__init__`

Metode konstruktor yang dijalankan saat objek `RecommenderNet` dibuat.

Tujuan: Menginisialisasi layer-layer yang dibutuhkan oleh model.

Parameter:
- `num_users`: Jumlah total user.
- `num_resto`: Jumlah total buku (dalam kode Anda, variabel ini bernama `num_book`).
- `embedding_size`: Dimensi ruang embedding untuk user dan buku.
- `**kwargs`: Argumen keyword tambahan yang diteruskan ke konstruktor `tf.keras.Model`.

Layer-layer:
- `user_embedding`: Layer embedding untuk user.
- `user_bias`: Layer bias untuk user.
- `resto_embedding`: Layer embedding untuk buku.
- `resto_bias`: Layer bias untuk buku.

Embedding: Teknik untuk merepresentasikan entitas diskrit (user dan buku) sebagai vektor dalam ruang kontinu. Ini memungkinkan model untuk mempelajari hubungan semantik antara user dan buku.

Bias: Nilai konstan yang ditambahkan ke output layer untuk meningkatkan fleksibilitas model.

###Metode `call`
Metode `call` mendefinisikan alur perhitungan (forward pass) model `RecommenderNet`. Ini adalah fungsi yang akan dijalankan ketika model di panggil dengan input data.

Tujuan utama metode `call` adalah untuk menghitung prediksi rating buku oleh user berdasarkan input berupa pasangan user dan buku.

Parameter:
- `inputs`: Tensor input yang berisi pasangan user dan buku yang telah dienkode. Bentuknya adalah `(batch_size, 2)`, di mana `batch_size` adalah jumlah sampel dalam satu batch dan 2 merepresentasikan kolom user dan buku.

Langkah-langkah Perhitungan:
1. Mendapatkan Embedding dan Bias:
- `user_vector = self.user_embedding(inputs[:,0])`: Mengambil vektor embedding untuk user dari layer `user_embedding` berdasarkan indeks user (`inputs[:,0]`).
- `user_bias = self.user_bias(inputs[:, 0])`: Mengambil bias untuk user dari layer `user_bias`.
- `resto_vector = self.resto_embedding(inputs[:, 1])`: Mengambil vektor embedding untuk buku dari layer `resto_embedding` berdasarkan indeks buku (`inputs[:,1]`).
- `resto_bias = self.resto_bias(inputs[:, 1])`: Mengambil bias untuk buku dari layer `resto_bias`.
2. Menghitung Dot Product:

`dot_user_resto = tf.tensordot(user_vector, resto_vector, 2)`: Menghitung dot product antara vektor embedding user dan buku. Dot product mengukur kemiripan antara kedua vektor.
3. Menambahkan Bias:

`x = dot_user_resto + user_bias + resto_bias`: Menambahkan bias user dan buku ke hasil dot product. Ini menambahkan fleksibilitas ke model dan memungkinkan untuk mempelajari pola interaksi yang lebih kompleks.
4. Menerapkan Fungsi Aktivasi Sigmoid:

`return tf.nn.sigmoid(x)`: Menerapkan fungsi aktivasi sigmoid pada hasil perhitungan. Sigmoid mengonversi output ke rentang 0 hingga 1, yang merepresentasikan prediksi rating.

Output: Metode `call` mengembalikan tensor yang berisi prediksi rating untuk setiap pasangan user dan buku dalam input. Bentuk tensor output adalah `(batch_size, 1)`.
"""

class RecommenderNet(tensorflow.keras.Model):

  def __init__(self, num_users, num_books, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_books = num_books
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.books_embedding = layers.Embedding(
        num_books,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.books_bias = layers.Embedding(num_books, 1)

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    books_vector = self.books_embedding(inputs[:, 1])
    books_bias = self.books_bias(inputs[:, 1])

    dot_user_books = tensorflow.tensordot(user_vector,books_vector, 2)

    x = dot_user_books + user_bias + books_bias

    return tensorflow.nn.sigmoid(x)

"""1. `model = RecommenderNet(num_users, num_book, 50)`:
- Membuat instance dari kelas `RecommenderNet`, yang telah didefinisikan sebelumnya.
- `num_users`: Jumlah total pengguna unik dalam dataset.
- `num_book`: Jumlah total buku unik dalam dataset.
- `50`: Dimensi ruang embedding untuk user dan buku (embedding size). Nilai ini dapat diubah sesuai kebutuhan.
2. `model.compile(...)`:
- Mengompilasi model dengan menentukan fungsi loss, optimizer, dan metrik evaluasi.
- `loss = tensorflow.keras.losses.BinaryCrossentropy()`: Fungsi loss yang digunakan untuk mengukur perbedaan antara prediksi model dan nilai rating sebenarnya. Binary Crossentropy cocok untuk kasus rating biner (misalnya, suka/tidak suka). Dalam kasus rating skala, seperti dalam dataset ini, mungkin lebih baik menggunakan fungsi loss lain seperti Mean Squared Error (MSE).
- `optimizer = keras.optimizers.Adam(learning_rate=0.001)`: Optimizer yang digunakan untuk mengupdate bobot model selama proses training. Adam adalah optimizer yang umum digunakan dalam deep learning. `learning_rate` menentukan seberapa besar langkah update bobot pada setiap iterasi.
- `metrics=[tensorflow.keras.metrics.RootMeanSquaredError()]`: Metrik yang digunakan untuk mengevaluasi performa model. Root Mean Squared Error (RMSE) mengukur rata-rata perbedaan kuadrat antara prediksi dan nilai rating sebenarnya.
"""

model = RecommenderNet(num_users, num_book, 50)

model.compile(
    loss = tensorflow.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tensorflow.keras.metrics.RootMeanSquaredError()]
)

"""- Melatih model menggunakan data training.
- `x = x_train`: Input data training (pasangan user dan buku yang dienkode).
- `y = y_train`: Output data training (nilai rating yang telah dinormalisasi).
- `batch_size = 5`: Jumlah sampel data yang diproses dalam setiap iterasi training.
- `epochs = 20`: Jumlah iterasi training pada seluruh dataset.
- `validation_data = (x_val, y_val)`: Data validasi yang digunakan untuk memantau performa model selama training.
"""

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 5,
    epochs = 20,
    validation_data = (x_val, y_val)
)

"""Sel di bawah digunakan untuk
- Memvisualisasikan metrik evaluasi (RMSE) selama proses training.
- Menampilkan grafik RMSE untuk data training dan data validasi.
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Sel di bawah digunakan untuk
- Memilih secara acak satu `user_id` dari DataFrame `ratings`.
- `sample(1)` mengambil satu sampel acak.
- `iloc[0]` mengambil nilai dari baris pertama (indeks 0) dari sampel tersebut.
- `user_id` akan menyimpan ID pengguna yang terpilih.
"""

user_id = ratings.user_id.sample(1).iloc[0]
books_have_been_read_by_user = ratings[ratings.user_id == user_id]

"""Sel di bawah digunakan untuk membuat DataFrame baru bernama `books_have_been_read_by_user` yang berisi semua rating buku yang telah diberikan oleh pengguna dengan `user_id` yang terpilih."""

books_have_not_been_read_by_user = book[book['book_ISBN'].isin(books_have_been_read_by_user.ISBN.values)]['book_ISBN']
books_have_not_been_read_by_user = list(
    set(books_have_not_been_read_by_user)
    .intersection(set(book_to_book_encoded.keys()))
)

"""Sel di bawah digunakan untuk
- Bagian ini bertujuan untuk mendapatkan daftar buku yang belum dibaca oleh pengguna.
- Pertama, mengambil semua `book_ISBN` dari buku yang telah dibaca oleh user.
- Kemudian, menggunakan `intersection` untuk menemukan buku-buku yang ada di dataset book dan juga di daftar buku yang telah dibaca.
- Terakhir, mengonversi `book_ISBN` ke dalam bentuk encoded menggunakan `book_to_book_encoded`.
"""

books_have_not_been_read_by_user = [[book_to_book_encoded.get(x)] for x in books_have_not_been_read_by_user]

"""Sel di bawah digunakan untuk mendapatkan representasi encoded dari `user_id` menggunakan dictionary `user_to_user_encoded`."""

user_encoder = user_to_user_encoded.get(user_id)

"""Sel di bawah digunakan untuk
- Membuat array `user_book_array` yang berisi pasangan `user_encoder` dan book_encoded untuk setiap buku yang belum dibaca oleh pengguna.
`[[user_encoder]] * len(books_have_not_been_read_by_user)`: Membuat array dengan `user_encoder` yang diulang sebanyak jumlah buku yang belum dibaca.
- `np.hstack`: Menggabungkan array `user_encoder` dan `books_have_not_been_read_by_user` secara horizontal.
"""

user_book_array = np.hstack(
    ([[user_encoder]] * len(books_have_not_been_read_by_user), books_have_not_been_read_by_user)
)

"""- Menggunakan model yang telah dilatih (`model`) untuk memprediksi rating buku yang belum dibaca oleh pengguna (`user_book_array`).
- `flatten()`: Mengubah hasil prediksi menjadi array satu dimensi.
"""

ratings = model.predict(user_book_array).flatten()

"""- Mendapatkan indeks 10 rating tertinggi dari hasil prediksi.
- `argsort()`: Mengembalikan indeks yang akan mengurutkan array.
- `[-10:][::-1]`: Mengambil 10 indeks terakhir (rating tertinggi) dan membalik urutannya.
"""

top_ratings_indices = ratings.argsort()[-10:][::-1]

"""- Mendapatkan `book_ISBN` dari buku-buku yang direkomendasikan berdasarkan `top_ratings_indices`.
- `book_encoded_to_book`: Digunakan untuk mendekode indeks buku kembali ke `book_ISBN`.
"""

recommended_book_ids = [
    book_encoded_to_book.get(books_have_not_been_read_by_user[x][0]) for x in top_ratings_indices
]

"""- Mendapatkan `book_ISBN` dari 5 buku dengan rating tertinggi yang telah dibaca oleh pengguna.
- Ini digunakan sebagai informasi tambahan untuk ditampilkan.
"""

top_books_recommended = (
    books_have_been_read_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .ISBN.values
)

"""- Menampilkan judul dan penulis dari 10 buku dengan rating tertinggi yang telah dibaca oleh pengguna."""

books_row = book[book['book_ISBN'].isin(top_books_recommended)]
for row in books_row.itertuples():
    print(row.book_title, ':', row.book_author)

print('----' * 8)
print('Top 10 Book Recommendation for user: {}'.format(user_id))
print('----' * 8)

recommended_books = book[book['book_ISBN'].isin(recommended_book_ids)]
for row in recommended_books.itertuples():
    print(row.book_title, ':', row.book_author)